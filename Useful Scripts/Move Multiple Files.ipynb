{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing\n",
    "Clean the autoflow results data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import time\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move data into folder\n",
    "Move failed data into failed folder, and success data into success folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files to run: 0 \n",
      "\n",
      "\n",
      " tot failed: 0\n",
      "tot success: 0\n"
     ]
    }
   ],
   "source": [
    "# file path\n",
    "dataFP = 'C:\\\\xx\\\\'\n",
    "\n",
    "# failed and success folder name\n",
    "failFN = 'FAILED'\n",
    "successFN = 'SUCCESS'\n",
    "\n",
    "# all data files in csv\n",
    "fullFNLists = glob.glob(dataFP + \"/*.csv\")\n",
    "\n",
    "# total files\n",
    "totFiles = len(fullFNLists)\n",
    "\n",
    "# print\n",
    "print ('Total files to run: %s \\n' % totFiles)\n",
    "\n",
    "# initialize\n",
    "totFail = 0\n",
    "totSuccess = 0\n",
    "hasError = False\n",
    "\n",
    "# for each file\n",
    "try:\n",
    "    for cnt, fn in enumerate(fullFNLists):\n",
    "\n",
    "        # file name\n",
    "        filename = os.path.splitext(os.path.basename(fn))[0]\n",
    "\n",
    "        # load message\n",
    "        sys.stdout.write(\"\\r %s. running '%s' file...\" % (cnt+1, filename))\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(0.1)\n",
    "\n",
    "        # if file name contains failed then move to failed folder, else move to success folder\n",
    "        if 'FAILED' in filename:\n",
    "            totFail = totFail + 1\n",
    "            shutil.move(fn,dataFP + failFN + '\\\\')\n",
    "        else:\n",
    "            totSuccess = totSuccess + 1\n",
    "            shutil.move(fn,dataFP + successFN + '\\\\')\n",
    "except:\n",
    "    print ('Error!')\n",
    "    hasError = True\n",
    "\n",
    "    \n",
    "if hasError == False:   \n",
    "    print ('\\n tot failed: %s' % totFail)\n",
    "    print ('tot success: %s' % totSuccess)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine all the success files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total success files: 90\n",
      " Append 90 file..."
     ]
    }
   ],
   "source": [
    "# all success data files in csv\n",
    "successFNLists = glob.glob(dataFP + successFN + \"/*.csv\")\n",
    "\n",
    "# total success folder\n",
    "totSuccessList = len(successFNLists)\n",
    "\n",
    "# initialize\n",
    "dfs = []\n",
    "combineError = False\n",
    "\n",
    "# print\n",
    "print ('Total success files: %s' %totSuccessList)\n",
    "\n",
    "# combine all files from the file path\n",
    "for cnt, fn in enumerate(successFNLists):\n",
    "\n",
    "    try:\n",
    "        # read data from csv\n",
    "        filedata = pd.read_csv(fn)\n",
    "        \n",
    "        # load message\n",
    "        sys.stdout.write(\"\\r Append %s file...\" % (cnt+1))\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "\n",
    "        # append it\n",
    "        dfs.append(filedata)    \n",
    "        \n",
    "    except:\n",
    "        print ('Error!')\n",
    "        combineError = True\n",
    "        break\n",
    "\n",
    "\n",
    "# concatenate\n",
    "if combineError == False:\n",
    "    dataAll = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to csv\n",
    "Write the data into csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder name\n",
    "cleanFN = 'CLEANED'\n",
    "\n",
    "# full file name\n",
    "writeFFN = dataFP + cleanFN + '\\\\' + 'successDataAll.csv'\n",
    "\n",
    "# write to csv\n",
    "dataAllTest.to_csv(writeFFN, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
