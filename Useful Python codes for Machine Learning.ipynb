{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Python codes for Machine Learning\n",
    "This notebook contains a list of scripts to train the machine learning model for my reference.\n",
    "<n>\n",
    "It is based on an udemy course \"Python for Data Science and Machine Learning Bootcamp\" by Jose Portilla <br>\n",
    "https://www.udemy.com/python-for-data-science-and-machine-learning-bootcamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USEFUL LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# machine learning\n",
    "# sklearn\n",
    "# tensorflow\n",
    "# keras\n",
    "\n",
    "# for linear regression, logistics regression, knn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# for spliting data into training and testing model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# for calculating MAE, MSE, RMSE (for linear regression)\n",
    "from sklearn import metrics\n",
    "\n",
    "# for getting the precision and confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# see visualisation in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Useful article\n",
    " https://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/\n",
    "\n",
    " In the data exploration, we want to\n",
    " - find the correlation between each column\n",
    " - check if there's any missing data\n",
    " - if there's missing data, see if you can impute(fill) the missing values by getting the other columns with good correlation, then use various methods and substitute the missing values. \n",
    " - Otherwise, drop it\n",
    " - check if there's any outliers\n",
    " - if there's outliers, find out why, and determine if you should drop or not\n",
    " - ** if outlier is incorrectly entered: drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA INFO\n",
    "# df = data\n",
    "# to get the info of the data\n",
    "df.info()\n",
    "\n",
    "# to show data columns\n",
    "df.columns\n",
    "\n",
    "# to show descriptive stats info of each columns (eg: mean, std_dev, min, max etc)\n",
    "df.describe()\n",
    "\n",
    "# to show the correlation of the data (which column has a good relationship with other column)\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZATIONS\n",
    "\n",
    "# to turn the seaborn plot style to whitegrid\n",
    "sns.set_style('whitegride')\n",
    "\n",
    "# PAIRPLOT: to see histograms of all the columns and correlation of scatterplots\n",
    "sns.pairplot(df)\n",
    "\n",
    "# to see histograms of all the columns and correlation, color code in a column\n",
    "sns.pairplot(df, hue='*column_name*')\n",
    "\n",
    "# HEATMAP: to show the correlation in heatmap\n",
    "sns.heatmap(df.corr(), annot=True)\n",
    "\n",
    "# HISTOGRAM: to check out the distribution & the frequency of a column\n",
    "# ** bins = range of values divided into xx equal parts\n",
    "# ** to turn off the kde, kde=False\n",
    "sns.distplot(df['*column_name*'], bins=30)\n",
    "\n",
    "# another way to plot distribution\n",
    "df['*column_name*'].plot.hist(bins=30)\n",
    "\n",
    "# to increase the size of the plot, use figsize = ()\n",
    "# plt.figure(figsize=(10,7)) or\n",
    "df['*column_name*'].hist(bins=30, figsize=(10,4))\n",
    "\n",
    "# BOXPLOT: useful for comparing distributions across groups & checkout outliers\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.boxplot(x='*x_column_name*',y='*y_column_name*', data=df)\n",
    "\n",
    "\n",
    "# CHECK MISSING DATA\n",
    "# to chekc missing data, use heatmap to check missing data, yellow strips = null values\n",
    "sns.heatmap(df.isnull(), yticklabels=False, cbar=False, cmap ='viridis')\n",
    "\n",
    "# to count a feature, use countplot, if adding categorize by another feature, include in hue\n",
    "# eg: count the number of titanic survivor by gender\n",
    "# sns.countplot(x='Survived', hue='Sex', data=df, palette='RdBu_r')\n",
    "sns.countplot(x='*column_name*', hue='*category_column_name*', data=df, palette='*color_name*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for interactive plot, you can use cufflinks\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "\n",
    "# eg: histogram interactive plot\n",
    "df['*column_name*'].iplot(kind='hist', bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "- Used when the dependent variable (the variable you want to predict,y) is numeric\n",
    "- linear approach to modelling the relationship between a scalar response and >= 1 explanatory variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOMNINATE X AND Y\n",
    "# X = featured data used to predict y\n",
    "# y = data you want to predict\n",
    "X = df[[]]\n",
    "y = df[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training set and testing set of the model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import linear regression model and create it\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN AND TEST THE MODEL\n",
    "# train the model \n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "# predict the testing sets\n",
    "predict = lm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZE THE RESULTS\n",
    "# to check out the preiction model compare to the actual, plot a scatter\n",
    "# if it shows straight line = quite a good model\n",
    "plt.scatter(y_test, predictions)\n",
    "\n",
    "# to check out the residuals, you can plot histogram of the distribution\n",
    "sns.distplot((y_test-predict))\n",
    "\n",
    "# ** RESIDUALS: difference between actual values of y test and the predicted values,\n",
    "# it's a measure of how well a predict line fits an individual actual data point, basically in the distribution plot\n",
    "# we want to get as much 0 as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL RESULTS: COEFFICIENTS\n",
    "# to check out the coefficient of each features\n",
    "lm.coef_\n",
    "\n",
    "# to make the coefficient into a table\n",
    "cdf = pd.DataFrame(lm.coef_, X.columns, columns=['Coeff'])\n",
    "cdf\n",
    "\n",
    "# coefficient tells you that a 1 unit increase in a feature is associated with an increase of a coefficient \n",
    "# of the predicted value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL RESULTS: EVALUATION METRICS\n",
    "# Evaluate metrics, basically: \n",
    "# - Mean Absolute Error (MAE)\n",
    "# - Mean Squared Error (MSE)\n",
    "# - Root Mean Squared Error (RMSE)\n",
    "# You want to minimize all of them, the smaller number the better\n",
    "from sklearn import metrics\n",
    "\n",
    "# Mean absolute error\n",
    "MAE = metrics.mean_absolute_error(y_test, predict)\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "MSE = metrics.mean_squared_error(y_test, predict)\n",
    "\n",
    "# Root Mean Squred Error (RMSE)\n",
    "RMSE = np.sqrt(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logitsitc Regression\n",
    "- used when the dependent variable is categorical (classification problem)\n",
    "- used to predict the odds of being a case based on the values of the independent variables (predictors,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical features using pandas' get_dummies\n",
    "# eg: turned Female & Male to 0 & 1 so that the ML algorithm will understand the categorical features\n",
    "# drop_first = True, you want to drop the 1st column since the other col already categorize it\n",
    "# eg: male column, 0 = female, 1 = male.\n",
    "cat_feat = pd.get_dummies(df['*column_name_to_transform*'], drop_first=True)\n",
    "\n",
    "# concatenate with the data\n",
    "df = pd.concat([cat_feat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOMINATE X AND Y\n",
    "X = df[[]] # only numerical featured values \n",
    "y = df[] # data you want to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training set and testing set of the model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logistic regression model and create it\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN AND TEST THE MODEL\n",
    "# train the model \n",
    "logmodel.fit(X_train, y_train)\n",
    "\n",
    "# predict the testing sets\n",
    "predict = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL RESULTS: EVALUATE THE MODEL\n",
    "# using classification report and confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# show classification report\n",
    "print(classification_report(y_test, predict))\n",
    "\n",
    "# show confusion matrix\n",
    "print(confusion_matrix(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix: <br>\n",
    "TN, FP <br>\n",
    "FN, TP <br>\n",
    "TN = true negatives, predict = no, actual = no <br>\n",
    "FP = False positive, predict = yes, actual = no <br>\n",
    "FN = false negative, predict = no, actual = yes <br>\n",
    "TP = true positive, predict =yes, actual = yes <br>\n",
    "<n>\n",
    "You would want to have a very high TN & TP and low FP & FN. \n",
    "\n",
    "<n>\n",
    "As for classification report, you would want a very high precision (close to 1)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbours\n",
    "- Supervised Technique\n",
    "- Used for Classification or Regression of known data where usually the target variable is known before hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Because the KNN and classifier predicts the class of a given test observation by identifying the observations that are nearest to it, the scale of the variable actually matters a lot, and any of the variables that have large scale, will have a much larger effect on the distance between observations. Thus when you use KNN you wanna standardized everything in the same scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCALE THE FEATURED DATA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fits the scaler to the data (finds the min, max, mean that will later use in its transform operation)\n",
    "# remember to drop the column you want to predict\n",
    "df_notc = df.drop('*y_column_name*', axis=1)\n",
    "scaler.fit(df_notc)\n",
    "\n",
    "# use scalar to do transformation\n",
    "scaled_feature = scaler.transform(df_notc)\n",
    "\n",
    "# create a table for scaled feature\n",
    "df_feat = pd.DataFrame(scaled_feature, columns=df_notc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOMINATE X AND Y\n",
    "X = df_feat #standardized featured data\n",
    "y = df[] #data you want to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training set and testing set of the model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import KNN model and create it\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_neighbors = 1 is k=1 <br>\n",
    "When tested with a new example, it looks through the training data and finds the k training examples that are closest to the new example. k thus is the number of neighbors considered. <br>\n",
    "eg: k=2, the 2 closest neighbors are used to smooth the estimate at a given point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN AND TEST THE MODEL\n",
    "# train the model \n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# predict the testing sets\n",
    "predict = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL RESULTS: EVALUATE THE MODEL\n",
    "# using classification report and confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# show classification report\n",
    "print(classification_report(y_test, predict))\n",
    "\n",
    "# show confusion matrix\n",
    "print(confusion_matrix(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will show the results with k=1, If the results aren't good, or if you wish to improve more, use elbow method (for loop) to pick the best k value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow method\n",
    "error_rate[]\n",
    "\n",
    "for i in range(1,40):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    \n",
    "    # append the error rate into the list\n",
    "    error_rate.append(np.mean(pred_i != y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the error rate\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,40), error_rate,color='blue', linestyle='--',marker='o',markersize=10,markerfacecolor='red')\n",
    "plt.title('Error Rate vs K Value')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you plot it, check which k value brings the lowest error rate, you would want to pick a number that has been consistently producing lower error rate before and after. \n",
    "<n>\n",
    "Once you've picked the k value, re-run the model again to check the precision and the confusion matrix to see if you're getting a better result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
